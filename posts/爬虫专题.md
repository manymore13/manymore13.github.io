## Requests
Requests是一个优雅而简单的Python HTTP库。

具体用法参考 [Home-page](https://requests.readthedocs.io/en/latest/)

---
## Scrapy
Scrapy是一个快速的高级网页抓取和网页抓取框架，用于抓取网站并从页面中提取结构化数据。它广泛用于数据挖掘到监控和自动化测试领域。
- [scrapy官网](https://docs.scrapy.org/)
- [scrapy-cookbook](https://scrapy-cookbook.readthedocs.io/zh_CN/latest/index.html)

---
## Selenium
`Selenium`是一个自动化测试工具，支持各种浏览器，包括Chrome、Safari、Firefox 等主流界面式浏览器。简单理解，Selenium可以模拟操作浏览器，对一些需要动态加载的页面，不需要我们执行JavaScript等操作，即可自动加载完成后的页面。

---
### 安装Selenium
直接使用pip安装
```bash
pip install selenium
```
我安装的版本是 Version: 4.9.0

- 安装Selenium之后，还需要下载对应的浏览器驱动

| [Chrome driver](https://sites.google.com/a/chromium.org/chromedriver/home) | [Firefox driver](https://github.com/mozilla/geckodriver/releases) | [IE driver](https://github.com/mozilla/geckodriver/releases) | [Edge driver](https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver) |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |

- 检查是否安装成功

```python
from selenium import webdriver
driver = webdriver.Edge()
driver.get("https://www.so.com/")
input("按任意键退出")
driver.quit()
```
若能正常打开浏览器，则安装成功

### 定位元素

```html
<ol id="vegetables">
 <li class="potatoes">…
 <li class="onions">…
 <li class="tomatoes"><span>Tomato is a Vegetable</span>…
</ol>
<ul id="fruits">
  <li class="bananas">…
  <li class="apples">…
  <li class="tomatoes"><span>Tomato is a Fruit</span>…
</ul>

```
以上面html为例，我们来定位元素
```python

from selenium import webdriver
from selenium.webdriver.common.by import By

# 通过class name定位
vegetable = driver.find_element(By.CLASS_NAME, "tomatoes")

# 通过id定位水果元素，再通过水果元素定位西红柿元素，这种嵌套定位效率不是最好的
fruits = driver.find_element(By.ID, "fruits")
fruit = fruits.find_element(By.CLASS_NAME,"tomatoes")

# 通过CSS 选择器定位元素
fruit = driver.find_element(By.CSS_SELECTOR,"#fruits .tomatoes")

# 通过标签名定位元素，这里是获取所有标签li   
plants = driver.find_elements(By.TAG_NAME, "li")


```

另外一个实例: 打开百度，然后搜索

```python
# 我的是微软Edge浏览器
driver = webdriver.Edge()
# 加载网页.
driver.get("https://www.baidu.com/")

title = driver.title
assert title == "百度一下，你就知道"

driver.implicitly_wait(0.5)
# 获取输入框元素
text_box = driver.find_element(by=By.ID, value="kw")
# 获取提交按钮元素
submit_button = driver.find_element(by=By.CSS_SELECTOR, value="#su")
# 输入关键词
text_box.send_keys("Selenium")
# 点击元素
submit_button.click()
# 暂停一下，再退出，否则代码走完程序都退出，浏览器会一闪而过
input("enter any key, quit")
# 关闭浏览器
driver.quit()
```


### 参考链接
- [selenium官网](https://www.selenium.dev/documentation/)
- [selenium使用教程](https://pythondjango.cn/python/tools/7-python_selenium/)




## 案例分享

>分享一个简单的例子：爬静态网页，通过requests获取网页html，再通过正则匹配内容，最后把内容下载保存到本地

[李敖回忆录](./src/crawl_xs.md)

---

## 其他
```bash
# 依赖项处理
pip freeze > requirements.txt
pip install -r requirements.txt
```
- [Python3网络爬虫开发实战](https://python3webspider.cuiqingcai.com/)
- [selenium提取不了标签文本](https://www.cnblogs.com/yfacesclub/p/11155775.html)
---
